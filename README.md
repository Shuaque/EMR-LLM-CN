# EMR-LLM-CN

EMR-LLM-CN is a **Qwen2.5-3B-Instruct**-based LLM that can process **multimodal dialogue inputs** and summarize them into **structured, label-based electronic medical records (EMR)**, supporting both **audio-visual speech recognition** and **EMR label generation**.

The code is protected by copyright. Please **credit the source** when using it, and **do not engage in infringement**.

![Overview](/workspace/shuaque/EMR-LLM-CN/data/examples/overview.png)


## Environment Setup
```bash

conda create -n emr python=3.9 -y
conda activate emr
git clone https://github.com/Shuaque/EMR-LLM-CN.git
cd EMR-LLM-CN

# PyTorch and related packages
pip install -U "pip<24.1" "setuptools<72" #(If your pip version > 24.1, please run this)
pip install "PyYAML>=5.1" "omegaconf==2.0.6" "hydra-core==1.0.7"


cd fairseq
pip install --editable ./

pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu121
pip install numpy==1.23.5 scipy opencv-python
pip install editdistance python_speech_features einops soundfile sentencepiece tqdm tensorboard unidecode librosa
pip install omegaconf==2.0.6 hydra-core==1.0.7 #(If your pip version > 24.1, please run "python3 -m pip install --upgrade pip==24.0")
pip install transformers==4.47.1 peft==0.14.0
pip install bitsandbytes --prefer-binary
pip install tensorboardX av matplotlib scikit-image

```
- Install `retinaface` at `../../EMR-LLM-CN/data/preparation/detectors/retinaface` tracker,you can put another detector in `../detectors`:
```bash
cd ../data/preparation/detectors/retinaface/
# Install [ibug.face_detection](https://github.com/hhj1897/face_detection)


git clone https://github.com/hhj1897/face_detection.git

# if its exisct in dir, than:
cd face_detection
pip install -e .
cd ..
```
- Recommendation: manually download to the specified directory, since errors frequently occur with `ibug/face_detection/retina_face/weights/Resnet50_Final.pth`.
```bash
Install [*`ibug.face_alignment`*](https://github.com/hhj1897/face_alignment)

git clone https://github.com/hhj1897/face_alignment.git

# if its exisct in dir, than:
cd face_alignment
pip install -e .
cd ..
```
- `Reference mean face download` from, than put it in `../detectors` same: [Line]( https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/blob/master/preprocessing/20words_mean_face.npy)


## Download 
1. Download Multimodal(audio-visual)EMR dataset generated by AI below, than put them in `../../EMR-LLM-CN/data`
2. Download model checkpoints for task `AVSR` & `EMR`,than than put them in `../../EMR-LLM-CN/pretrianed`
3. Download `avhubert` checkpoint, than put it in `../../EMR-LLM-CN/pretrained/Avhubert/base_vox_iter5.pt`
4. Download `whisper` from huggingface or modelscope platform, then put it in `../../EMR-LLM-CN/pretrained/Whisper/whisper-large`
5. Download `whisper` from huggingface or modelscope platform, then put it in `../../EMR-LLM-CN/pretrained/LLM/Qwen2.5-3B-Instruct`


| File Name              | Source URL                                                                              | File Size  |
|------------------------|-----------------------------------------------------------------------------------------|------------|
| CMDD-MIE-EMR-AV        |[GoogleDrive](https://drive.google.com/drive/folders/1XjJ0T5kQ-ntyWc_2M1EHZJxpba1c9FId?usp=sharing) or [BaiduDrive](https://pan.baidu.com/s/1FI7JZw8aSFEoO13X405SBg)(key: cize) |     18GB   |
| emr_checkpoint_best.pt        |[GoogleDrive]() or [BaiduDrive]()(key: ) |     8.3GB   |
| avsr_checkpoint_best.pt        |[GoogleDrive]() or [BaiduDrive]()(key: ) |     8.3GB   |


Some results are slightly better than in the paper due to hyper-parameter optimisation. The av-asr code and checkpoint can be found on the released version.


## Inference
Run the script `../../EMR-LLM-CN/inference.py` to perform **single-sample evaluation**. Built-in evaluation examples are provided, supporting EMR data across **text-only**, **audio-video**, and **audio-only** modalities. Example multimodal data can be found in `../../EMR-LLM-CN/data/examples`, where audio or video samples are provided for evaluation.
```bash
export ROOT=../../EMR-LLM-CN
export TOKENIZERS_PARALLELISM=false
export SRC_PTH="$ROOT/src"
export PYTHONPATH=$ROOT:$ROOT/fairseq:$SRC_PTH

CHECKPOINT=/workspace/shuaque/Classification_Semantic_att_LLM/exp/202512/run/28190745_A800_Optimized_Exp1_3_B_3_loss/checkpoints/checkpoint_best.pt

CUDA_VISIBLE_DEVICES=0 python $ROOT/inference.py \
    --common-user-dir /workspace/shuaque/EMR-LLM-CN/src \
    --checkpoint-path $CHECKPOINT \
    --ontology-path /workspace/shuaque/EMR-LLM-CN/data/ontology.json \
    --device cuda:0
```

Example results can be found in `../../EMR-LLM-CN/inference.log`.
```bash
| [Pipeline] Processing Dialogue Inputs...

============================================================
| Final Context for EMR Model:
============================================================
患者:没有呕吐,就是吐了点奶,
医生:宝宝今天吐奶几次
患者:一次
医生:血丝多吗
医生:呕吐物中有粘液吗?
============================================================

| [EMR] Running entity extraction...

[Top-10 Probabilities]
Rank  1 | Prob: 0.9934 | 症状:呕吐
Rank  2 | Prob: 0.7551 | 症状:大便粘液
Rank  3 | Prob: 0.3389 | 症状:血便
Rank  4 | Prob: 0.0722 | 症状:大便黏液
Rank  5 | Prob: 0.0541 | 症状:稀便
Rank  6 | Prob: 0.0226 | 症状:蛋花汤样便
Rank  7 | Prob: 0.0169 | 症状:退热
Rank  8 | Prob: 0.0148 | 症状:咳痰
Rank  9 | Prob: 0.0145 | 症状:痰
Rank 10 | Prob: 0.0144 | 症状:咳嗽

------------------------------------------------------------
[Summary: Final Predicted Labels (Threshold > 0.5)]
 - 症状:大便粘液
 - 症状:呕吐
============================================================


| [Pipeline] Processing Dialogue Inputs...

============================================================
| Final Context for EMR Model:
============================================================
患者:心脏的血管堵塞有什么最新治疗方法吗
医生:您好,要看在什么部位,一般可以下支架解决堵塞问题!CT未看到堵塞,有肌桥,若症状较重考虑搭桥手术!
============================================================

| [EMR] Running entity extraction...

[Top-10 Probabilities]
Rank  1 | Prob: 1.0000 | 手术:支架
Rank  2 | Prob: 0.9998 | 手术:搭桥
Rank  3 | Prob: 0.9843 | 症状:心肌梗死
Rank  4 | Prob: 0.8889 | 症状:冠心病
Rank  5 | Prob: 0.3260 | 症状:胸闷
Rank  6 | Prob: 0.1104 | 症状:乏力
Rank  7 | Prob: 0.0650 | 症状:水肿
Rank  8 | Prob: 0.0535 | 症状:高血压
Rank  9 | Prob: 0.0409 | 症状:呼吸困难
Rank 10 | Prob: 0.0263 | 手术:介入

------------------------------------------------------------
[Summary: Final Predicted Labels (Threshold > 0.5)]
 - 症状:心肌梗死
 - 症状:冠心病
 - 手术:搭桥
 - 手术:支架
============================================================


| [Pipeline] Processing Dialogue Inputs...

============================================================
| Final Context for EMR Model:
============================================================
医生:在看化验单
医生:就这个大便结果来看,是病毒合并细菌感染,这两个药可以继续吃,孩子大便还是不见好吗?
患者:是的
患者:还要给他添点别的药吗?昨天好一点,今天又开始了
医生:大便是什么样子?能拍个图片吗?
============================================================

| [EMR] Running entity extraction...

[Top-10 Probabilities]
Rank  1 | Prob: 0.9270 | 症状:细菌感染
Rank  2 | Prob: 0.6570 | 症状:病毒感染
Rank  3 | Prob: 0.0319 | 症状:退热
Rank  4 | Prob: 0.0226 | 症状:腹泻
Rank  5 | Prob: 0.0183 | 症状:痢疾
Rank  6 | Prob: 0.0175 | 症状:病毒性肠炎
Rank  7 | Prob: 0.0155 | 症状:轮状病毒感染
Rank  8 | Prob: 0.0152 | 症状:细菌性肠炎
Rank  9 | Prob: 0.0146 | 症状:大便粘液
Rank 10 | Prob: 0.0144 | 症状:细菌性感冒

------------------------------------------------------------
[Summary: Final Predicted Labels (Threshold > 0.5)]
 - 症状:细菌感染
 - 症状:病毒感染
============================================================


| [Pipeline] Processing Dialogue Inputs...

============================================================
| Final Context for EMR Model:
============================================================
医生:你好,有具体彩超单子吗?
患者:有,刚满月拍的彩超。现在孩子三个月了
医生:拍一个完整的
患者:
医生:孩子现在有什么症状吗?
============================================================

| [EMR] Running entity extraction...

[Top-10 Probabilities]
Rank  1 | Prob: 1.0000 | 检查:彩超
Rank  2 | Prob: 0.0486 | 检查:b超
Rank  3 | Prob: 0.0264 | 检查:超声
Rank  4 | Prob: 0.0239 | 检查:体检
Rank  5 | Prob: 0.0111 | 症状:先天性心脏病
Rank  6 | Prob: 0.0102 | 检查:血常规
Rank  7 | Prob: 0.0098 | 症状:心律不齐
Rank  8 | Prob: 0.0090 | 症状:甲亢
Rank  9 | Prob: 0.0065 | 检查:心肌酶
Rank 10 | Prob: 0.0052 | 症状:发绀

------------------------------------------------------------
[Summary: Final Predicted Labels (Threshold > 0.5)]
 - 检查:彩超
============================================================

```



## Batch evaluation on EMR data
Ensure that `test.json` is stored in `../data`, and that `$CHECKPOINT` has been downloaded and placed in the `../../EMR-LLM-CN/pretrained` directory. The `--ratios` option can be set within `[0.1–1.0]` to reduce the number of candidate labels and thereby shorten the evaluation time. The evaluation results are saved in `../../EMR-LLM-CN/results/`.The script at `../../EMR-LLM-CN/scritps/eval_emr.sh`. Also, view example results in `../../EMR-LLM-CN/results/emr_eval_sweep.log`.


```bash
export ROOT=../../EMR-LLM-CN
export TOKENIZERS_PARALLELISM=false
export SRC_PTH="$ROOT/src"
export PYTHONPATH=$ROOT:$ROOT/fairseq:$SRC_PTH

CHECKPOINT=../EMR-LLM-CN/pretrained/emr_checkpoint_best.pt

CUDA_VISIBLE_DEVICES=0 python3 $SRC_PTH/eval.py \
    --common-user-dir $SRC_PTH \
    --checkpoint-path $CHECKPOINT \
    --split test \
    --device cuda:0 \
    --output-dir $ROOT \
    --ratios 1.0
```


## Batch evaluation on audio-visual data
Store the audio-video path file `test.tsv` and the corresponding text label file `test.ltr` in `$DATA`. The audio-video path file should contain `id, role, video_path, audio_path, video_frames, audio_frames`, and the label file should contain `id, role, text`. Alternatively, modify the dataset class `../../EMR-LLM-CN/scr_avsr/dataset.py`.More details, as shown in the **Train for Audio-Visual Speech Recognotion** section below. Also, view example results in `../../EMR-LLM-CN/results/avsr_eval_log.txt`.

```bash
#! /bin/bash

export ROOT=../../EMR-LLM-CN
export SRC_PTH=$ROOT/src_avsr
export PYTHONPATH=$ROOT:$ROOT/fairseq:$SRC_PTH

LLM_PATH=$ROOT/pretrained/LLM/Qwen2.5-3B-Instruct
Whisper_PATH=$ROOT/pretrained/Whisper/whisper-large
Avhubert_PATH=$ROOT/pretrained/Avhubert/base_vox_iter5.pt
CTC_VOCAB=$ROOT/data/global_ctc_vocab_3bi.pt

DATA=../CMDD-MIE-EMR-AV

# Fine-tuned model path (Checkpoint)
MODEL_PATH=$ROOT/exp/202601/run/train_21_214647/checkpoints/checkpoint_best.pt
OUT_PATH=$ROOT/results/

CUDA_VISIBLE_DEVICES=0 python -B $SRC_PTH/eval.py \
  --config-dir ${SRC_PTH}/conf \
  --config-name eval \
  common.user_dir=${SRC_PTH} \
  common_eval.path=${MODEL_PATH} \
  common_eval.results_path=${OUT_PATH} \
  dataset.gen_subset=test \
  model.w2v_path=${Avhubert_PATH} \
  model.whisper_path=${Whisper_PATH} \
  model.ctc_vocab_path=${CTC_VOCAB} \
  override.llm_path=${LLM_PATH} \
  override.data=${DATA} \
  override.label_dir=${DATA} \
  override.modalities="['audio','video']" \
  override.noise_wav=${ROOT}/data/babble_noise.wav \
  override.noise_prob=0.0 \
  override.noise_snr=0
```

## Train for EMR Generation
Ensure that the **text-only EMR dataset** is stored in `../data/test.json | train.json | dev.json`,
the **training script** is located at `../../EMR-LLM-CN/scirpts/train_emr.sh`,change the parameters settings at `../../EMR-LLM-CN/src/conf/train.yaml`, and the **training logs** are saved in `../../EMR-LLM-CN/exp`.

```bash
# #!/usr/bin/env bash
# set -euo pipefail

export ROOT=../../EMR-LLM-CN
export TOKENIZERS_PARALLELISM=false
export SRC_PTH="$ROOT/src"
export CONF_DIR="$SRC_PTH/conf"
export CONF_NAME="train.yaml"

export PYTHONPATH="$ROOT/fairseq"
export CUDA_VISIBLE_DEVICES=0,1,2,3
NGPUS=4

fairseq-hydra-train \
  --config-dir "$CONF_DIR" \
  --config-name "$CONF_NAME" \
  common.user_dir="$SRC_PTH" \
  distributed_training.distributed_world_size=$NGPUS

```

## Train for Audio-Visual Speech Recognotion 
Ensure that the **Audio-Visual dataset** is stored in `../data/test.tsv | train.tsv | valid.tsv`, with each entry formatted as `id, role, video_path, audio_path, video_frames, audio_frames`, and that the corresponding **text labels** are stored in `../data/test.ltr | train.ltr | valid.ltr`, formatted as `id, role, text`, for example:

```bash

# train.tsv
cmdd_dia_78_win_5            pat     ../../train/video96/cmdd_dia_78_win_5.mp4        ../../train/audio16k/cmdd_dia_78_win_5.wav        37      23680
S0116_M-0116-1_014176-014616 NA      ../../train/video/S0116_M-0116-1_014176-014616.mp4 /wav16k/S0116/S0116_M-0116-1_014176-014616.wav      110     70400
cmdd_dia_377_win_30          pat     ../../train/video96/cmdd_dia_377_win_30.mp4        ../../train/audio16k/cmdd_dia_377_win_30.wav        38      24320

# train.ltr
cmdd_dia_78_win_5            pat     精神都很好
S0116_M-0116-1_014176-014616 unknown 阳光下万物生长生命在这土地上蓬勃
cmdd_dia_377_win_30          pat     她咳了都一个星期了

```
The **training script** is located at `../../EMR-LLM-CN/scirpts/train_avsr.sh`,change the parameters settings at `../../EMR-LLM-CN/src_avsr/conf/train_avsr.yaml`, and the **training logs** are saved in `../../EMR-LLM-CN/exp`.

```bash
#!/usr/bin/env bash
set -euo pipefail

export ROOT=../../EMR-LLM-CN
SRC_PTH="$ROOT/src_avsr"
CONF_DIR="$SRC_PTH/conf"
CONF_NAME="train_avsr"
export TOKENIZERS_PARALLELISM=false
export PYTHONPATH="$ROOT/fairseq"

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64
NGPUS=4

CUDA_VISIBLE_DEVICES=0,1,2,3 fairseq-hydra-train \
  --config-dir "$CONF_DIR" \
  --config-name "$CONF_NAME" \
  common.user_dir="$SRC_PTH" \
  distributed_training.distributed_world_size="$NGPUS" \
  distributed_training.nprocs_per_node="$NGPUS"
```